\documentclass[11pt]{article}
\title{Analysis: Association between sodium consumption and life expectancy at age 30}
\author{Kellie Ottoboni}

\usepackage{amsmath,amssymb,amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}

\usepackage{graphicx,float}
\usepackage[margin=0.75in]{geometry}
\usepackage{bm}
\usepackage[backend=bibtex]{biblatex}
\usepackage{hyperref}

\newcommand{\ind}{\mathbb{I}} % Indicator function
\newcommand{\pr}{\mathbb{P}} % Generic probability
\newcommand{\ex}{\mathbb{E}} % Generic expectation
\newcommand{\normal}{N} % for normal distribution 
\newcommand{\eps}{\varepsilon}
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}


\begin{document}

\maketitle

<<knitr_options, include=FALSE>>=
library(knitr)
library(xtable)
opts_chunk$set(fig.width=12, fig.height=4, fig.path='RmdFigs/',
               warning=FALSE, message=FALSE, echo=FALSE)
@

<<load_data>>=
set.seed(38)
library(dplyr)
library(reshape2)
library(ggplot2)
library(Hmisc)
library(randomForest)
library(sandwich)
library(lmtest)
library(plm)
library(stargazer)
library(rpart)
library(cluster)
@
\section{Introduction}
If salt is bad for you, then we'd expect 
\begin{enumerate}
\item ceteris paribus, salt would be negatively associated with life expectancy.
\item salt would be a strong predictor of life expectancy after accounting for other important factors.
\end{enumerate}
We assess these points in a variety of ways below.
We find that neither point is satisified.
Sodium consumption is not significantly negatively correlated with life expectancy, and it isn't a strong predictor of life expectancy after accounting for alcohol consumption, cigarette consumption, and per capita GDP.

On the other hand, we'd expect these other three factors to be more strongly associated with life expectancy.
Alcohol and cigarettes are known to cause negative health outcomes, both short-term and long-term.
Indeed, our analyses confirm these hypotheses: alcohol and smoking are negatively associated with and are strong predictors of life expectancy.
Thus, we have confidence that the methods we explore below are able to detect an effect when the effect is actually present.


\section{Data cleaning}

Data preprocessing includes removing unwanted variables (we keep alcohol consumption and per capita cigarette consumption only) and imputing the missing values of the predictors. In particular:

\begin{itemize}
\item We merge two data sources. One contains the economic variables, life expectancy, alcohol, and sodium consumption. The other contains the annual number of cigarettes smoked per capita.
\item We impute the missing 2010 sex-specific alcohol consumption for Taiwan using a linear regression of male and female life expectancy, male and female salt consumption, per capita GDP, and per capita annual cigarette consumption on sex-specific alcohol consumption. Then we impute population average alcohol consumption by taking a weighted average of male and female alcohol consumption, using the proportion of the population that is male/female as the weights.
\item We impute the missing 1990 overall alcohol consumption for Taiwan in the same way as before, regressing predictors on overall alcohol consumption. Then we use the proportion of alcohol consumption in 2010 attributable to males and females to estimate the male and female sex-specific alcohol consumption in 1990, respectively.
\end{itemize}

<<impute>>=
salt <- read.table("../Data/omnibus_data.csv", sep = "\t", header = TRUE)
salt <- salt %>% mutate("etoh_M" = etohM, "etoh_F" = etohF)
smoke <- read.table("../Data/smoking_t14.csv", sep = ",", header = TRUE)
smoke <- dplyr::select(smoke, country_name_p, annual_pc_smoking_1990, annual_pc_smoking_2010)


salt <- mutate(salt, popF_prop = popF/(popF + popM), popM_prop = popM/(popF + popM))
salt$popF_prop[is.na(salt$popF)] <- 0.5; salt$popM_prop[is.na(salt$popM)] <- 0.5
salt$etohboth <- ifelse(is.na(salt$etohboth), salt$popM_prop*salt$etoh_M + salt$popF_prop*salt$etoh_F, salt$etohboth)

salt <- arrange(salt, country, year)
salt_filt <- dplyr::select(salt, country, country_name_p, e0_M, e0_F, year, Na_M, Na_F, etohboth, etoh_M, etoh_F, pc_gdp, popM_prop, popF_prop)

salt2010 <- filter(salt_filt, year == 2010)
salt2010 <- merge(smoke, salt2010)
salt2010 <- dplyr::select(salt2010, -annual_pc_smoking_1990, -country_name_p) %>% mutate(smoking = annual_pc_smoking_2010) %>% dplyr::select(-annual_pc_smoking_2010)
etoh_M_mod <- lm(etoh_M~ e0_M + e0_F + Na_M + Na_F + pc_gdp + smoking, data = salt2010)
etoh_F_mod <- lm(etoh_F~ e0_M + e0_F + Na_M + Na_F + pc_gdp + smoking, data = salt2010)
twn <- which(is.na(salt2010$etoh_M))
salt2010[twn, "etoh_M"] <- predict(etoh_M_mod, salt2010[twn,]); salt2010[twn, "etoh_F"] <- predict(etoh_F_mod, salt2010[twn,])
salt2010[twn, "etohboth"] <- (salt2010$popM_prop*salt2010$etoh_M + salt2010$popF_prop*salt2010$etoh_F)[twn]

salt1990 <- filter(salt_filt, year == 1990)
salt1990 <- merge(smoke, salt1990)
salt1990 <- dplyr::select(salt1990, -annual_pc_smoking_2010, -country_name_p)  %>% mutate(smoking = annual_pc_smoking_1990) %>% dplyr::select(-annual_pc_smoking_1990)
etohboth_mod <- lm(etohboth ~ e0_M + e0_F + Na_M + Na_F + pc_gdp + smoking, data = salt1990)
twn <- which(is.na(salt1990$etohboth))
salt1990[twn, "etohboth"] <- predict(etohboth_mod, salt1990[twn,])
salt1990$etoh_M     <- salt1990$etohboth * (salt2010$etoh_M)/(salt2010$popM_prop*salt2010$etoh_M+salt2010$popF_prop*salt2010$etoh_F)
salt1990$etoh_F     <- salt1990$etohboth * (salt2010$etoh_F)/(salt2010$popM_prop*salt2010$etoh_M+salt2010$popF_prop*salt2010$etoh_F)
@

<<malefemale_diff>>=
countries <- salt2010$country
salt_diff <- salt2010[,-1]-salt1990[,-1]
salt_diff <- cbind(countries, salt_diff)
salt_diff <- filter(salt_diff, !is.na(e0_M))

male_diff <- dplyr::select(salt_diff, e0_M, etoh_M, smoking, Na_M)
colnames(male_diff) <- gsub("_M", "", colnames(male_diff))
female_diff <- dplyr::select(salt_diff,  e0_F, etoh_F, smoking, Na_F)
colnames(female_diff) <- gsub("_F", "", colnames(female_diff))
@

<<malefemale_absolute>>=
salt_absolute <- rbind(salt1990, salt2010)
salt_absolute$year <- c(rep("1990", nrow(salt1990)), rep("2010", nrow(salt2010)))
salt_absolute <- salt_absolute %>% filter(!is.na(e0_M) & !is.na(e0_F))
male_absolute <- dplyr::select(salt_absolute, e0_M, country, year, etoh_M, smoking, Na_M)
colnames(male_absolute) <- gsub("_M", "", colnames(male_absolute))
female_absolute <- dplyr::select(salt_absolute, e0_F, country, year, etoh_F, smoking, Na_F)
colnames(female_absolute) <- gsub("_F", "", colnames(female_absolute))
@
\section{Correlations}
\subsection{Raw Correlations}
First, we report the raw correlations between life expectancy at age 30 and each of the predictors.
This does not control for correlations between predictors.
It is the crudest measure.
Table~\ref{tab:raw_corr} shows these correlations.
For alcohol, smoking, and per capita GDP, the sign of the correlations are consistent across all four cuts of the data and are consistent with our expectations.
Sodium is negatively associated with life expectancy for males but positively associated for females.

<<raw_corr, echo=FALSE, results="asis", cache=TRUE>>=

compute_correlations <- function(outcome, variables){
  correlations <- rep(NA, ncol(variables))
  names(correlations) <- colnames(variables)
  for(j in seq_len(ncol(variables))){
    correlations[j] <- cor(outcome, variables[,j])
  }
  return(correlations)
}

m1 <- compute_correlations(male_diff$e0, male_diff %>% select(-e0))
f1 <- compute_correlations(female_diff$e0, female_diff %>% select(-e0))
m2 <- compute_correlations(male_absolute$e0, male_absolute %>% select(-e0, -country, -year))
f2 <- compute_correlations(female_absolute$e0, female_absolute %>% select(-e0, -country, -year))

corr_tab <- cbind(m1, m2, f1, f2)
corr_tab <- rbind(c("Male", "", "Female", ""), rep(c("Differenced", "Cross-sectional"), 2), round(corr_tab, 2))
rownames(corr_tab)[1:2] <- c("", "  ")
print(xtable(corr_tab, align = "r|rr|rr", 
             caption = "Raw correlations with life expectancy at age 30.",
             label = "tab:raw_corr"),
      include.rownames = TRUE,
      include.colnames = FALSE,
      hline.after = c(0, 1, 2, nrow(corr_tab)))
@

\subsection{Permutation Tests}
We'd like to assess how significantly correlated each variable is with life expectancy, accounting for the other confounding variables.
We do this by conducting stratified permutation tests.
This data is observational, not randomized, so observations are not exchangeable without some assumptions.
We use the idea of a balancing score from Rosenbaum and Rubin (1983).
A balancing score is a function $b(X)$ of the covariates $X$ that makes treatment assignment $T$ conditionally independent of covariates:
$$X \independent T \mid b(X).$$
If we stratify on a balancing score, we may permute observations within strata.

For this to yield a valid test, we essentially need to model the balancing score correctly.
This relies on the assumption that we account for all causal variables in $X$.
We don't believe that we have included everything that may affect life expectancy at age 30.
However, we would like to proceed with the method.
For robustness, we try two different balancing scores: the generalized propensity score and the prognostic score.
If results using the two balancing scores are qualitatively similar, then we have some assurance that the assumption may not be badly violated.

\subsection{Generalized Propensity Score}
Hirano and Imbens (2004) introduce the idea of a \textit{generalized propensity score} for continuous treatments.
% http://scholar.harvard.edu/files/imbens/files/hir_07feb04.pdf?m=1360041978
% there is probably a more recent paper on this
They assume \textit{weak unconfoundedness}:
\begin{assumption}[Weak unconfoundedness] $Y(t) \independent T \mid X \text{ for all } t \in T$.
\end{assumption}
This essentially means that we've accounted for all potential confounders in $X$.
Then, they define the generalized propensity score:

\begin{definition}[Generalized propensity score]
Let $r(t, x)$ be the conditional density of the treatment given the covariates:
$$r(t, x) = f_{T | X} (t|x).$$ 
Then the generalized propensity score is $R = r(T, X)$.
\end{definition}

The generalized propensity score has the following mechanical property:

$$X \independent \ind\{T = t\} \vert r(t, X)$$
This means that treatment assignment is unconfounded given the generalized propensity score.
Practically speaking, within strata of units with the same $r(T, X)$, the level of treatment for each country amounts to an arbitrary labelling.
This suggests a procedure to conduct a permutation test for the effect of treatment:
\begin{enumerate}
\item Estimate the generalized propensity score using a linear probability model for treatment given covariates.
Formally, $T \sim \normal(X\beta, \sigma^2)$.
Then, for unit $i$, the GPS estimate is

$$ R_i = \frac{1}{\sqrt{2\pi\hat{\sigma}^2}}\exp\left(-\frac{(T_i - x_i'\hat{\beta})^2}{2\hat{\sigma}^2}\right)$$
Note, we could fit distributions other than the normal by maximum likelihood if desired. 
\item Stratify observations on the estimated GPS. 
We use k-means to partition the GPS into bins. 
We choose the number of strata $k$ to have smallest average silhouette width; this will be data-dependent.
\item Do a stratified permutation test for correlation between treatment and outcomes.
\end{enumerate}


\subsection{Prognostic Score}
We do the same thing using the prognostic score, the predicted outcome using no information on the treatment (Hansen, 2008).
We use CART to predict the outcome and create strata.

\subsection{Balance Tests}
There are several ways we may run into trouble using this method.
First, we must estimate the generalized propensity score and prognostic score.
If either model is misspecified (which in this case, it likely is), then the score which we use to stratify may result in grouping the wrong countries.
Second, we must choose how to stratify.
We do this in a somewhat arbitrary way.
For the generalized propensity score, we divide the countries by quintiles of the estimated scores.
For the prognostic score, we use the leaves of the regression tree that we use to estimate the score.
Both methods have arbitrary tuning parameters.

Both scores are balancing scores, so that strata formed using them should be ``balanced'' on all confounding variables.
That is, there should be no correlation between the treatment level and any of the covariates within strata.
To test this, we use the same stratified permutation test of correlation that we use to test the association between treatment and outcome, except here we apply it to treatment and each covariate.

Tables~\ref{tab:gps_balance_m}--\ref{tab:prog_balance_f} show the results of these balance tests, for both male and female data and both balancing scores.
For the most part, the stratification acheives balance: most of the p-values are large.
However, when using the generalized propensity score to stratify and test for association between salt and life expectancy, the strata do not balance the covariates.
The p-values for association between sodium consumption and alcohol and smoking are near or exactly zero for both males and females, and the p-value for per capita GDP is zero for males.
Thus, the permutation tests based on this stratification method may not be valid and their results should be taken with a grain of salt (pun intended).

\subsection{Results}
Figure~\ref{fig:do_corr_plots_m1} shows the results for males using the differenced data (2010-1990).
Based on the tests using the generalized propensity score stratification, sodium, and alcohol are all significantly associated with life expectancy at age 30.
The p-values for association are all above 10\% when considering the tests using prognostic score stratification.

Figure~\ref{fig:do_corr_plots_f1} shows the results for females using the differenced data (2010-1990).
No variable is significantly associated with life expectancy using either stratification method.
\textcolor{red}{Sodium consumption has the smallest p-value, just above 10\% for both methods.
Recall that for females, the correlation between sodium and life expectancy is actually positive; thus this result says that sodium has a nonsignificant association with \textit{increases} in life expectancy at age 30.
}

The p-values do not, in general, show close agreement between the two stratification methods.
Stratification on the generalized propensity score tends to give smaller p-values than stratification on prognostic scores.
Aside from this, the results suggest that after controlling for the other variables in the dataset, we did not identify a statistically significant association between increases in sodium consumption and decreases in life expectancy.
This does not give evidence for the ``salt is bad'' hypothesis.

\clearpage
<<generalized_matching_tests, echo=FALSE>>=
compute_prognostic_score <- function(outcome, covariates){
  dataset <- cbind(outcome, covariates)
  colnames(dataset)[1] <- "outcome"
  mod <- rpart(outcome~., dataset)
  return(predict(mod))
}

compute_gps <- function(dataset, treatment = "Na"){
  # Pass in the name of the treatment var as a string
  if(any(colnames(dataset) == "e0")){dataset <- dataset %>% select(-e0)}
  if(any(colnames(dataset) == "country")){dataset <- dataset %>% select(-country)}
  if(any(colnames(dataset) == "year")){dataset <- dataset %>% select(-year)}
  
  # Model Na as Normal(Xbeta, sigma^2)
  formula <- as.formula(paste(treatment, "~.", collapse = ""))
  mod <- lm(formula, dataset)
  sigmahat <- summary(mod)$sigma
  mu <- predict(mod)
  # Find probability of the observed Na given the model and X
  gps <- pnorm(dataset$Na, mu, sigmahat)
  # Use a tree to partition
#  gps_blocking <- rpart(gps~., data = cbind(dataset, gps) %>% select(-Na))
#  return(predict(gps_blocking))
  return(gps)
}


predictions_to_strata_gps <- function(pred){
  return(cut(pred, quantile(pred, probs = seq(0, 1, 0.2)), include.lowest = TRUE))
}


predictions_to_strata <- function(pred){
  return(rank(pred))
}

within_group_corr <- function(strata, variable, treatment){
  groups <- sort(unique(strata))
  sapply(groups, function(g){
    index <- which(strata == g)
    return(abs(cor(variable[index], treatment[index])))
  })
}

permute_within_groups <- function(strata, treatment){
  permuted <- treatment
  groups <- sort(unique(strata))
  for(g in groups){
    permuted[strata==g] <- sample(treatment[strata==g])
  }
  return(permuted)
}


# Carry out a stratified permutation test for the Pearson correlation between a variable and treatment.
#
# strata = vector of stratum assignments
# variable = vector of the variable of interest
# treatment = vector of treatments
# iters = The number of Monte Carlo iterations (default 1000)
#
# Returns a list containing the results: attributes estimate (the estimated sum of abs correlations), distr (simulated permutation distribution), and pvalue (p-value for the test)
permu_pearson <- function(strata, variable, treatment, iters = 1000){
  weights <- table(strata)/length(variable)
  obs <- sum(within_group_corr(strata, variable, treatment)*weights)
  distr <- replicate(iters, {
    tr <- permute_within_groups(strata, treatment)
    sum(within_group_corr(strata, variable, tr)*weights)
  })
  pval <- sum(distr >= obs)/iters
  return(list("estimate" = obs, "distr" = distr, "pvalue" = pval))
}


test_corr_strata <- function(outcome, dataset, iters = 1000){
  # Loop through all the covariates in dataset and test for correlation using the GPS and prognostic score
  pvalues <- matrix(NA, ncol = 2, nrow = ncol(dataset))
  rownames(pvalues) <- colnames(dataset)
  colnames(pvalues) <- c("Generalized Propensity Score", "Prognostic Score")
  
  prog_balance_test <- matrix(NA, ncol = ncol(dataset), nrow = ncol(dataset))
  gps_balance_test <- matrix(NA, ncol = ncol(dataset), nrow = ncol(dataset))
  
  rownames(prog_balance_test) <- rownames(gps_balance_test) <- colnames(dataset)
  colnames(prog_balance_test) <- colnames(gps_balance_test) <- colnames(dataset)

  for(j in seq_len(ncol(dataset))){
    treat <- dataset[,j]
    name_treat <- colnames(dataset)[j]
    vars  <- dataset[,-j]
    # GPS
    pred <- compute_gps(dataset, treatment = name_treat)
    strata <- predictions_to_strata_gps(pred)
    pvalues[j, 1] <- permu_pearson(strata, outcome, treat, iters = iters)$pvalue
    
    # GPS Balance tests
    for(k in seq_len(ncol(dataset))[-j]){
      gps_balance_test[j, k] <- permu_pearson(strata, treat, dataset[,k], iters = iters)$pvalue
    }
    
    # Prognostic score
    pred <- compute_prognostic_score(outcome, dataset)
    strata <- predictions_to_strata(pred)
    pvalues[j, 2] <- permu_pearson(strata, outcome, treat, iters = iters)$pvalue
    
    # Prognostic score Balance tests
    for(k in seq_len(ncol(dataset))[-j]){
      prog_balance_test[j, k] <- permu_pearson(strata, treat, dataset[,k], iters = iters)$pvalue
    }
  }
  return(list(
    "pvalues" = pvalues[nrow(pvalues):1,],
    "gps_balance" = gps_balance_test,
    "prog_balance" = prog_balance_test)
  )
}

plot_corr_pvalues <- function(pvalues){
  # Create a plot of p-values

  res2plot <- melt(pvalues)
  colnames(res2plot) <- c("Variable", "Score", "pvalue")
  
  p <- ggplot(res2plot, aes(x = pvalue, y = Variable)) + 
    geom_point(size = 5, aes(color=Score, shape=Score)) + 
    geom_vline(xintercept = 0.05, linetype = "dotted") +   
    geom_vline(xintercept = 0.1, linetype = "dotted") + 
    xlab("P-value") + ylab("") +
    ggtitle("P-value for Correlation with Life Expectancy at Age 30") +
    theme_bw() + 
    scale_x_continuous(breaks = c(0, 0.05, 0.1, 0.25, 0.5, 0.75), limits = c(0, 0.9)) +
    theme(axis.text = element_text(size = 16)) +
    theme(axis.title = element_text(size = 16)) +
    theme(legend.text = element_text(size = 16)) + 
    theme(title = element_text(size=20)) +
    theme(legend.position = "bottom")
  return(p)
}

print_balance_tables <- function(balance_matrix, label, caption){
  xtable(balance_matrix, align = "r|rrr",
         label = label,
         caption = caption)
}
@

<<do_corr_plots_m1, echo=FALSE, cache=TRUE, fig.cap = "P-values for males, differenced (2010-1990).">>=
set.seed(10101)
pvalues_m <- test_corr_strata(male_diff$e0, male_diff %>% select(-e0)) 
plot_corr_pvalues(pvalues_m$pvalues)  

@
<<do_balance_tables_m, results="asis">>=
print_balance_tables(pvalues_m$gps_balance, label = "tab:gps_balance_m", caption = "P-values from balance tests within strata formed by GPS, for male data.
                    Rows are the notional treatment and columns are covariates.")
print_balance_tables(pvalues_m$prog_balance, label = "tab:gps_balance_m", caption = "P-values from balance tests within strata formed by prognostic score, for male data.
                    Rows are the notional treatment and columns are covariates.")
@
<<do_corr_plots_m2, echo=FALSE, cache=TRUE, fig.cap = "P-values for males, cross-sectional.", eval=FALSE>>=

set.seed(10103) 
pvalues <-  test_corr_strata(male_absolute$e0, male_absolute %>% select(-e0, -country, -year))
plot_corr_pvalues(pvalues)
@
<<do_corr_plots_f1, echo=FALSE, cache=TRUE, fig.cap = "P-values for females, differenced (2010-1990).">>=
set.seed(10102)
pvalues_f <- test_corr_strata(female_diff$e0, female_diff %>% select(-e0))
plot_corr_pvalues(pvalues_f$pvalues)  
@
<<do_balance_tables_f, results="asis">>=
print_balance_tables(pvalues_f$gps_balance, label = "tab:gps_balance_f", caption = "P-values from balance tests within strata formed by GPS, for female data.
                    Rows are the notional treatment and columns are covariates.")
print_balance_tables(pvalues_f$prog_balance, label = "tab:gps_balance_f", caption = "P-values from balance tests within strata formed by prognostic score, for female data.
                    Rows are the notional treatment and columns are covariates.")
@
<<do_corr_plots_f2, echo=FALSE, cache=TRUE, fig.cap = "P-values for females, cross-sectional.", eval=FALSE>>=
set.seed(10104) 
pvalues <-  test_corr_strata(female_absolute$e0, female_absolute %>% select(-e0, -country, -year))
plot_corr_pvalues(pvalues)
@

\clearpage
\section{Variable importance}

In his seminal paper on random forests, Leo Breiman introduced a variable importance measure based on permutations. 
The idea is that if a variable is important in a regression, then perturbing it will worsen the predictive performance. 
On the other hand, if we perturb a variable and the predictions remain relatively good, then the variable is not important to the model. 
We perturb the variables by permuting them, breaking the association between the feature and all other variables and the outcome.

Though the idea of permutation variable importance came from random forests, it is sufficiently general that it can apply to any predictive model. 
We can use several metrics for this: 
we report the ``absolute importance,'' the original root mean squared error (RMSE) minus average permuted RMSE, and the ``normalized importance,'' the absolute importance divided by the original RMSE. 
Large values indicate more importance.

\subsection{Results}
We compare several prediction methods: CART, random forests, OLS, and OLS with interaction terms.
We run each function using default tuning parameters.
Alcohol is the most important predictor across all models except for CART.
\textcolor{red}{CART is interesting: after pruning, the final tree for males only inludes per capita GDP and the final tree for females includes per capita GDP and sodium.
For such a simple model, 
Sodium intake appears to be the least important predictor for different methods for males. 
However, it is not least important in any model for the female data; smoking appears least important here.
}

<<variable_importance, echo=FALSE>>=
compute_rmse <- function(prediction, truth){
  sqrt(mean((prediction-truth)^2, na.rm=TRUE))
}

permutation_variable_importance <- function(Xmat, Y, model, nperm = 1000){
  # Carry out permutation variable importance
  # Input:
  # Xmat  = a matrix or dataframe of features
  # Y     = a vector of outcomes, one for each row in Xmat
  # model = a model object to be passed into predict
  # nperm = number of permuted datasets to simulate. Default 1000

  baseline_rmse <- compute_rmse(predict(model, Xmat), Y)
  p <- ncol(Xmat)
  Xmat_perm <- Xmat
  RMSEmat <- matrix(NA, nrow = nperm, ncol = p)
  colnames(RMSEmat) <- colnames(Xmat)
  for(i in seq_len(p)){
    RMSEmat[,i] <- replicate(nperm, {
      Xmat_perm[,i] <- sample(Xmat_perm[,i])
      compute_rmse(predict(model, Xmat_perm), Y)
    })
  }
  avg_permuted_rmse <- apply(RMSEmat, 2, mean)
  avg_variable_importance <- baseline_rmse - avg_permuted_rmse
  normalized_variable_importance <- avg_variable_importance/baseline_rmse
  return(list(
    "importance" = -1*avg_variable_importance,
    "normalized" = -1*normalized_variable_importance
    ))
}

compute_variable_importance <- function(dataset){
  # Takes as input a dataframe with both X and Y (e0)
  # Outputs variable importance for each feature, according to a bunch of different models
  Xmat = dataset %>% dplyr::select(-e0)
  Y = dataset %>% dplyr::select(e0)
  model_list <- list(
    "CART"                  = rpart(e0~., data = dataset),
    "Random Forest"         = randomForest(e0~., data = dataset),
    "OLS"                   = lm(e0~., data = dataset),
    "OLS with interactions" = lm(e0~(.)^2, data = dataset)
  )
  lapply(model_list, function(mod) permutation_variable_importance(Xmat, Y, mod, nperm = 100))
}

permutation_importance_table <- function(perm_imp, title){
  abs <- do.call(rbind, lapply(perm_imp, function(x) x[[1]]))
  abs <- round(abs, 3)
  norm <- do.call(rbind, lapply(perm_imp, function(x) x[[2]]))
  norm <- round(norm, 3)
  p <- ncol(abs)
  tab <- rbind(c("Absolute", rep("", p-1), "Normalized", rep("", p-1)), rep(colnames(abs, 2)), cbind(abs, norm))
  rownames(tab)[1:2] <- c("", "  ")
  print(xtable(tab, align = "r|lll|lll",
               caption = title),
        include.rownames = TRUE,
        include.colnames = FALSE,
        hline.after = c(0, 1, 2, nrow(tab)))
} 
@

 
<<do_variable_importance, echo=FALSE, results = "asis", cache=TRUE>>=
compute_variable_importance(male_diff) %>% permutation_importance_table(title = "Variable importance for males, differenced (2010-1990)") 
compute_variable_importance(female_diff) %>% permutation_importance_table(title = "Variable importance for females, differenced (2010-1990)")
@

\subsection{Alternative Variable Importance for Random Forests}
The default variable importance measure in \texttt{randomForest} is different from what we described above.
Instead of permuting the predictor of interest and evaluating the full model on this perturbed dataset, the function does the permutation procedure for each individual tree used in growing the random forest.
The final importance measure is the average decrease in mean squared error across trees in the forest.

Figure~\ref{fig:rf_variable_importance} shows these measures when we train a random forest with the default R settings.
Note that we report root mean squared error in the previous section, so the scales are different.
\textcolor{red}{Although the order of importance varies slightly, the trend is the same for both the male and female datasets: alcohol and per capita GDP are substantially more important than smoking and sodium.}

Figure~\ref{fig:rf_partial_plots} shows the partial dependency plots for each variable.
We use the random forest to estimate the marginal effect of each variable on changes in life expectancy at age 30 from 1990 to 2010, holding the other variables fixed at their observed values.
These figures suggest that each variable has a large effect (steep positive or negative slope, graphically) only locally.
\textcolor{red}{For instance, increases of \$0 to \$10,000 in per capita GDP seem to have a large positive association with increased life expectancy, but increases in per capita GDP larger than \$10,000 have little to no effect.
Similarly, decreases in cigarettes per capita seem to have no association with life expectancy, while increases in cigarettes per capita have a negative association with life expectancy.
The findings for sodium are less clear.
It appears that for males, only increases in sodium consumption over 0.2 grams per day are associated with decreases in life expectancy.
For females, any increase in sodium consumption is associated with increased life expectancy.
Compared to the other variables, the magnitude of changes in life expectancy according to sodium consumption are smaller; the curves for alcohol and per capita GDP fill the entire plot frame, while the curves for sodium span half of that range.
}

We've considered variable importance in several manners, and all confirm that sodium is a less important predictor than alcohol \textcolor{red}{and per capita GDP.}
Because the dataset is small and parts of the covariate space may be sparse, we should be careful not to place too much weight in these results.
Furthermore, this measure of variable importance is specific to the random forest models that we estimated.
One must bear in mind that importance may depend on the choice of model.

<<rf_variable_importance, fig.align = "center", fig.height = 6, fig.width = 12, cache=TRUE, fig.cap = "Variable importance measure from the \texttt{randomForest} package.">>=

male_rf <- randomForest(e0~., male_diff, importance = TRUE)
female_rf <- randomForest(e0~., female_diff, importance = TRUE)
importanceOrder=order(male_rf$importance)
importance_mat <- list(data.frame(importance(male_rf), "Sex"=rep("Male", 3)), 
                       data.frame(importance(female_rf), "Sex"=rep("Female", 3))) %>% 
                  do.call(rbind, .) %>% 
                  mutate("Covariate" = rownames(.)) %>%
                  melt(id.vars = c("Sex", "Covariate"))
importance_mat[, "Covariate"] <- gsub("1", "", importance_mat[, "Covariate"])

importance_mat %>% filter(variable == "IncNodePurity") %>%
  mutate("Covariate" = factor(Covariate, levels = rownames(male_rf$importance)[importanceOrder])) %>%
  ggplot(aes(x = value, y = factor(Covariate))) +
  geom_point(size = 3) +
  facet_grid(~Sex, scales = "free") +  
  theme_bw() +
  theme(title = element_text(size = 18),
        axis.title = element_text(size=18),
        axis.text = element_text(size=15),
        strip.text.x = element_text(size=18)) +
  xlab("Increase in Node Purity") +
  ylab("Exposure") +
  ggtitle("Random Forest Importance")
#par(mfrow=c(1,2))
#varImpPlot(male_rf,type=2)
#varImpPlot(female_rf,type=2)
@
<<rf_partial_plots, fig.align = "center", fig.height = 6, fig.width = 12, cache=TRUE, fig.cap = "Partial dependency plots for each of the four variables. They display the estimated marginal effect of the variable on change in life expectancy at age 30 from 1990 to 2010.">>=

importanceOrder2=order(-male_rf$importance[,1])
names=rownames(male_rf$importance)[importanceOrder2]
plot_data <- vector("list", 3)
for(i in 1:3){
  name <- names[i]
  m1 <- partialPlot(male_rf, male_diff, eval(name), plot = FALSE)
  f1 <- partialPlot(female_rf, female_diff, eval(name), plot=FALSE)
  x <- c(m1$x, f1$x)
  y <- c(m1$y, f1$y)
  plot_data[[i]] <- data.frame(
                    "x"=x, 
                    "y"=y, 
                    "var"=rep(name, length(x)),
                    "Sex"=c(rep("Male", length(m1$x)), rep("Female", length(f1$x))))
}
plot_data <- do.call(rbind, plot_data)
ggplot(plot_data, aes(x = x, y = y)) + 
  geom_line(aes(color = Sex)) +
  facet_wrap(~var, scales = "free") +
  ylim(2.1, 4.3) +
  theme_bw() + 
  theme(legend.position = "bottom",
        title = element_text(size = 18),
        axis.title = element_text(size=18),
        axis.text = element_text(size=15),
        legend.title = element_text(size=18,face="plain"),
        legend.text = element_text(size=15),
        strip.text.x = element_text(size=18)) +
  xlab("Change in Exposure Level") +
  ylab("") +
  ggtitle("Partial Dependency Plots \n Difference in Life Expectancy at Age 30 (2010 - 1990)")
@

\newpage

\section{Linear models}

<<linear_models, echo=FALSE>>=

compute_linear_models_differenced <- function(dataset){
  # Takes in a dataset of differenced measures
  mod0 <- lm(e0~Na, data=dataset)
  OLS_plain <- coeftest(mod0)
  robust_plain <- coeftest(mod0, vcov = vcovHC(mod0, type = "HC1"))
  
  mod1 <- lm(e0~Na+etoh, data=dataset)
  OLS_etoh <- coeftest(mod1)
  robust_etoh <- coeftest(mod1, vcov = vcovHC(mod1, type = "HC1"))

  mod2 <- lm(e0~Na+etoh+smoking, data=dataset)
  OLS_etoh_smoke <- coeftest(mod2)
  robust_etoh_smoke <- coeftest(mod2, vcov = vcovHC(mod2, type = "HC1"))
  return(list(
    "OLS plain" = OLS_plain,
    "robust plain" = robust_plain,
    "OLS etoh" = OLS_etoh,
    "robust etoh" = robust_etoh,
    "OLS etoh smoke" = OLS_etoh_smoke,
    "robust etoh smoke" = robust_etoh_smoke
  ))
}

compute_fixed_effects <- function(dataset){
  # Takes in a dataset with a column of years and country names
  predictors <- colnames(dataset %>% dplyr::select(-e0, -country, -year))
  predictors <- paste(predictors, collapse = "+")
  
  mod0 <- plm(e0~Na+factor(year), data = dataset, index=c("country","year"), model = "within")
  fe0 <- coeftest(mod0, vcov = vcovHC(mod0, type = "HC1"))

  mod1 <- plm(e0~Na+etoh+factor(year), data = dataset, index=c("country","year"), model = "within")
  fe1 <- coeftest(mod1, vcov = vcovHC(mod1, type = "HC1"))

  mod2 <- plm(e0~Na+etoh+smoking+factor(year), data = dataset, index=c("country","year"), model = "within")
  fe2 <- coeftest(mod2, vcov = vcovHC(mod2, type = "HC1"))
  OLS2 <- coeftest(mod2)

  return(list(
    "plain" = fe0,
    "etoh"  = fe1,
    "etoh smoke" = fe2,
    "OLS" = OLS2
  ))
}
@
\subsection{Fixed Effects Model}
First, we look at the data cross-sectionally.
To account for unobserved confounding variables, we add a fixed effect term for each country.
The key assumption (aside from the usual linear model/response schedule assumptions) is that these country-specific effects do not change over time; all that changes is the treatment over time.
This amounts to estimating a different intercept for each country.
We need to correct the standard errors when we estimate this way by using the Huber-White Sandwich estimator.
Let the subscript $i$ denote country and $t$ denote time period.
The model is

$$Y_{it} = \alpha_i + \lambda_t + \beta_1\text{ETOH}_{it} +  \beta_2\text{SMOKE}_{it} + \gamma\text{Na}_{it} + \eps_{it}$$
$\alpha_i$ is the fixed effect for country $i$.
$\lambda_t$ is a time effect.

We're interested in the parameter $\gamma$.
\textcolor{red}{If salt were detrimental to health, we'd expect $\gamma$ to be negative.
We find the opposite: in all fixed effect specifications that we run, salt has a significant positive effect on life expectancy at age 30.
In the OLS models, salt has no significant association with life expectancy.
In the full fixed effects model for males (column (6) in Table~\ref{tab:mfe}), a one unit increase in sodium consumption is associated with an increase in life expectancy of $3.004$ years (significant at 10\% level).
For females (column (6) in Table~\ref{tab:ffe}), it's associated with a $6.06$ year increase in life expectancy (significant at 1\% level).}

<<do_fixed_effects, results="asis", echo=FALSE, cache=TRUE>>=
compute_fixed_effects(male_absolute) %>% stargazer(style = "qje",
                                                   title = "Male cross-sectional data",
                                                   label = "tab:mfe",
                                                   column.labels = c("Fixed Effects","Fixed Effects","Fixed Effects","OLS", "Robust", "Fixed Effects"),
                                                   notes = "")
compute_fixed_effects(female_absolute) %>% stargazer(style = "qje",
                                                     title = "Female cross-sectional data",
                                                     label = "tab:ffe",
                                                     column.labels = c("Fixed Effects","Fixed Effects","Fixed Effects","OLS", "Robust", "Fixed Effects"),
                                                     notes = "")
@

\subsection{Differenced Model}
Next, we look at conventional linear models for the differenced data. 
We have measurements from 1990 and 2010 for each country.
If we take the difference, we can estimate

$$\Delta Y_{it} =  \Delta \lambda_t + \beta_1\Delta \text{ETOH}_{i} + \beta_2\Delta \text{SMOKE}_{i} + \gamma\Delta \text{Na}_{i} + \Delta \eps_{i}$$
This eliminates the need for fixed effects.
However, this model assumes constant additive treatment effects.
In particular,
\begin{enumerate}
\item Any country that increases its Na+ consumption by 1 unit will shift its life expectancy by $\gamma$.
\item Trends in life expectancy would be the same in all countries in the absence of treatment (salt consumption).
\end{enumerate}

We report usual OLS standard errors as well as Huber-White robust standard errors.

If salt were detrimental, then we'd expect to see a negative coefficient in the linear model.
\textcolor{red}{
We do observe a negative coefficient for males, when we don't include any other variables in the model.
However, as soon as we add alcohol to the model, the association disappears because increases in alcohol consumption explain a large portion of the decrease in life expectancy.
We focus on the full model including alcohol, smoking, and per capita GDP.
For males (column (8) in Table~\ref{tab:mlm}), a one unit increase in sodium consumption from 1990 to 2010 is associated with an increase in life expectancy of $0.271$ years.
For females (column (8) in Table~\ref{tab:flm}), it's associated with a $2.073$ year increase in life expectancy between 1990 and 2010 (significant at 10\% level).
}

<<do_linear_models, results="asis", echo=FALSE, cache=TRUE>>=
compute_linear_models_differenced(male_diff) %>% stargazer(style = "qje",
                                                           title = "Male, differenced regressions (2010-1990)",
                                                           label = "tab:mlm",
                                                           column.labels = rep(c("OLS", "Robust"), 4),
                                                           notes = "")
compute_linear_models_differenced(female_diff) %>% stargazer(style = "qje",
                                                           title = "Female, differenced regressions (2010-1990)",
                                                           label = "tab:flm",
                                                           column.labels = c("OLS", "Robust"),
                                                           notes = "")
@
\clearpage


\section{R and package versions used}
<<sessionInfo, include=TRUE, echo=TRUE, results='markup'>>=
sessionInfo()
@

\end{document}